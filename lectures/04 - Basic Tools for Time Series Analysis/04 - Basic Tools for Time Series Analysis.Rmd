---
title: "ISA 444: Business Forecasting"
subtitle: "04 - Basic Tools for Time Series Analysis"
author: Fadel M. Megahed
date: 'Spring 2021'
output:
  beamer_presentation:
    number_sections: false
    toc: false
    slide_level: 3
    includes: 
      in_header: structure.txt
classoption: "aspectratio=169"
always_allow_html: yes
bibliography: refs.bib
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      verbose = FALSE,
                      progress = FALSE,
                      fig.align = "center",
                      fig.pos = 'p',
                      fig.width = 5.95,
                      fig.height= 2.5,
                      allowframebreaks = TRUE,
                      fig.margin=TRUE,
                      kable.force.latex = TRUE,
                      cache = FALSE)
options(kableExtra.latex.load_packages = FALSE)
pacman::p_load(kableExtra, tidyverse, xtable)
```

# Preface

### What we Covered Last Class

\begin{block}{\textbf{Main Learning Outcomes}}
			$\quad$ \textcolor{darkgreen}{\large \checkboxFadel} \textbf{Explain different goals for visualizing time series data} \\
			$\quad$ \textcolor{miamired}{\large \checkboxFadel} \textbf{Identify an appropriate chart for a specific time series data visualization goal} \\
			$\quad$ \textcolor{miamired}{\large \checkboxFadel} \textbf{Use software to construct charts of interest} \\
\end{block}

\textcolor{darkgreen}{\textbf{For the last two bullets, we only described the univariate case.}}


### A Structured Approach for Time Series Visualization

\vspace{\baselineskip}

\begin{figure}
		\centering
		\adjustbox{max width=\textwidth, frame}{%
			\begin{forest}
				[\Large{\textbf{Time Series Visualization}}
				[\textcolor{miamired}{\textbf{\large Singular Time Series}}
				[\textbf{Plot the Entire Series}
				[Look for
				[\textit{Trends}]
				[\textit{Seasonality}]
				[\textit{Cycles}]
				[\textit{Motifs}
				[High Freq. TS]]]]]
				[\textcolor{miamired}{\textbf{\large Multiple Time Series}}
				[\textbf{Few Series}
				[Scatterplots]
				[Paneled Line Plots
				[Look for
				[\textit{Trends}]
				[\textit{Seasonality}]
				[\textit{Cycles}]]]]
				[\textbf{Many Series}
				[\textcolor{miamired}{Sample} 
				[Panel/Combined Plots]]
				[\textcolor{miamired}{All TS}
				[Cluster
				[Summary Plot]
				[Spaghetti Plot]]]]]]
		\end{forest}}
		\caption{A Potential Framework for Time Series Visualization.\footnotemark}
	\end{figure}

\vspace{-\baselineskip}

\footnotetext{This is my best attempt to improve on the general advice provided in the previous slide. Many of the suggestions, presented in this flow chart, stem from my past and current research/consulting collaborations. They are by no means a comprehensive list of everything that you can do.}


### Learning Objectives for Today's Class
\begin{block}{\textbf{Main Learning Outcomes}}
  \begin{itemize}
			\item \textbf{Use numerical summaries to describe a time series.} \\
			\item \textbf{Apply transformations to a time series.}
	\end{itemize}
\end{block}


# Time Series Plots (Continued from Last Class)
## A Singular Time Series

### Looking for Motifs based on Wearable Sensors Data

Motifs allow us to cluster subsequences of a time series. It is a popular (unsupervised) learning approach, where patterns are automatically detected in time series. 

\begin{figure}
  \centering
  \includegraphics[width=\textwidth, height = 0.45\textheight, keepaspectratio]{Figures/ladder.png}
  \caption{Three dominant motifs discovered in an electrical utility application.\footnotemark}
\end{figure}

\footnotetext{Joint Work with GE Research and the University at Buffalo. Recall that the sensors had a frequency of 60Hz per \href{https://miamioh.instructure.com/courses/142177/files/18921236?module_item_id=2897312}{Slide 25 in Lecture 02 Notes.}}


## Multiple Time Series

### Scatterplots [1]

- **Scatterplots** are frequently used to visualize the correlation between two continuous variables. 

- In this Example, we will be using the [German_Forecast Data](https://www.wessexlearning.org/pobf2e/index.html). The file can be downloaded to your working directory, using the `download.file()` from base R.  

- Note that the data is an xlsx file, which would require us to use the `read_excel()` from the [readxl package](https://readxl.tidyverse.org/). 

- We will remake the plot of GDP vs Govsurp (Figure 2.4 in our textbook) using R. As noted in the chapter, the figure was created using Minitab for the book.  

- The plot using the `ggplot()` is shown in the next slide. We will recreate it in class.


### Scatterplots [2]

```{r germanForecastScatter, echo=FALSE}
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(tidyverse, lubridate, readxl)
download.file("https://www.wessexlearning.org/pobf2e/dsa/German_forecasts.xlsx",
              destfile = "Data/German_forecasts.xlsx", mode = "wb")
dfGerman = read_excel("Data/German_forecasts.xlsx")
dfGerman %>% ggplot(aes(x = Govsurp, y = GDP)) +
  geom_point() + 
  labs(title = "Scatterplot of GDP vs. Government Spending",
       caption = "Data from Muller-Droge et al. (2016)") + theme_bw()
```

### Scatterplot Matrix / Generalized Pairs Plots [1]

- Extending scatterplots for when we have more than two variables.\footnotemark  

- Can be easily created in R using the ``ggpairs()`` from the [GGally package](https://ggobi.github.io/ggally/articles/ggpairs.html). 


\footnotetext{John W Emerson, Walton A Green, Barret Schloerke, Jason Crowley, Dianne Cook, Heike Hofmann, Hadley Wickham.
The Generalized Pairs Plot.
Journal of Computational and Graphical Statistics, vol. 22, no. 1, pp. 79â€“91, 2012. \href{http://vita.had.co.nz/papers/gpp.pdf}{Click here to access paper}.}


### Scatterplot Matrix / Generalized Pairs Plots [2]

```{r scpMatrix, echo = FALSE}
pacman::p_load(tidyverse, GGally)
dfGerman %>% # object created from the example in the previous slide
  ggpairs(columns = c('GDP', 'GFCF', 'Govsurp', 'Unemp')) + 
  labs(title = "Matrix Plot of GDP, GFCF, Govsurp & Unemp",
       caption = "Data from Muller-Droge et al. (2016)") + theme_bw(base_size = 8)
```

### Panel Plots

\begin{figure}
  \centering
  \includegraphics[width=\textwidth, height = 0.7\textheight, keepaspectratio]{Figures/motivationPlot.png}
  \caption{New COVID-19 Cases in the United States.\footnotemark}
\end{figure}

\footnotetext{Joint Work with Saint Louis University.}


### Clustering of COVID-19 New Cases: Spaghetti Plot

\begin{figure}
  \centering
  \includegraphics[width=\textwidth, height = 0.7\textheight, keepaspectratio, trim = {0 0.5in 0 0.5in}, clip]{Figures/spaghetti-1.png}
  \caption{Spaghetti Plot of the 3 Major Clusters of COVID-19 Time-Series Profile Shapes.\footnotemark}
\end{figure}

\footnotetext{Joint Work with Saint Louis University.}

### Clustering of COVID-19 New Cases: Summary Plot

\begin{figure}
  \centering
  \includegraphics[width=\textwidth, height = 0.7\textheight, keepaspectratio, trim = {0 0.5in 0 0.5in}, clip]{Figures/summaryPlot-1.png}
  \caption{Summary Plot of the 3 Major Clusters of COVID-19 Time-Series Profile Shapes.\footnotemark}
\end{figure}

\footnotetext{Joint Work with Saint Louis University.}



# Summarizing Time Series Data

### Measures of Average
**Mean:** Given a set of $n$ values $Y_1, \, Y_2, \, \dots, \, Y_n$, the arithmetic mean can be computed as:

\begin{equation}
\bar{Y} = \frac{Y_1 + Y_2 + \dots + Y_n}{n} = \frac{1}{n}\sum_{i=1}^{i=n}Y_i.
\end{equation}

**Order Statistics:**
Given a set of $n$ values $Y_1, \, Y_2, \, \dots, \, Y_n$, we place them in an ascending order to define the order statistics, written as $Y_{(1)}, \, Y_{(2)}, \, \dots, \, Y_{(n)}.$

**Median:**  

  - If $n$ is odd, $n = 2m + 1$ and the median is $Y_{(m+1)}$.   
  - If $n$ is even, $n = 2m$ and the median is the average of the two middle numbers, i.e.,  $\frac{1}{2}[Y_{(m)} + Y_{(m+1)}]$.


### Measures of Variation

The **range** denotes the difference between the largest and smallest value in a sample:  
\begin{equation}
\text{Range} = Y_{(n)} - Y_{(1)}.
\end{equation}

The **deviation** is defined as the difference between a given observation $Y_i$ and the mean $\bar{Y}$.

The **mean absolute deviation (MAD)** is the average deviations about the mean, irrespective of their sign:
\begin{equation}
\text{MAD} = \frac{\sum_{i=1}^{i=n}|d_i|}{n}.
\end{equation}

The **variance** is the average of the squared deviations around the mean:  
\begin{equation}
S^2 = \frac{\sum_{i=1}^{i=n}d_i^2}{n-1}.
\end{equation}


### A Comment on the `mad()` Function in R

- The `mad()` in R is used for computing the median absolute deviation and **Not** the mean absolute deviation. This can be easily checked using `?mad()` in your R console.  

- Thus, we will have to create our custom R function, `MAD()`, which we will define as follows: 
```{r MAD}
MAD = function(x){
  return( mean( abs(x-mean(x)) ) )
  }
```

- Now, let us make sure that this formula works as expected by testing it on the vector `x = c(1, 2, 3)` and comparing it with manually computing the MAD.


### Applications of Measures of Average/Variance: $GME
- Let us examine the stock prices for [GameStop](https://finance.yahoo.com/quote/GME/) from September 01, 2020 up to January 31, 2021. 

- Let us compute the aforementioned measures, on the adjusted closing price, using the following two approaches: (a) averages **across** all months, and (b) averages **by/within** month. The printout for those two methods are shown in the tables below.

```{r gme, echo= FALSE, results='asis'}
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(tidyquant, lubridate, magrittr)
gamestop = tq_get("GME", from = "2020-09-01", to = "2021-01-31") %>% 
  select(symbol, date, adjusted)
gamestop$month = month(gamestop$date, label = TRUE) %>% 
  factor(levels = c('Sep', 'Oct', 'Nov', 'Dec', 'Jan'),
         labels = c('Sep 2020', 'Oct 2020', 'Nov 2020', 'Dec 2020', 'Jan 2021'))
gamestop %>% summarise(meanACP = mean(adjusted),
                            medianACP = median(adjusted),
                            madACP = MAD(adjusted),
                            varACP = var(adjusted),
                            sdACP = sd(adjusted) ) -> gmeSummary

print(xtable(gmeSummary, align = c(rep('c', 6))), comment = FALSE, size = '\\scriptsize', include.rownames=FALSE)

gamestop %>% group_by(month) %>% summarise(meanACP = mean(adjusted),
                            medianACP = median(adjusted),
                            madACP = MAD(adjusted),
                            varACP = var(adjusted),
                            sdACP = sd(adjusted) ) -> gmeSummary

print(xtable(gmeSummary, align = c(rep('c', 7))), comment = FALSE, size = '\\scriptsize', include.rownames=FALSE)
```


# Correlation

### The Pearson Correlation Coefficient

- **Correlation:** measures the strength of the **linear relationship** between two
quantitative variables.

- It can be computed using the `cor()` from base R. Mathematically speaking, the pearson correlation coefficient, $r$, can be computed as

\begin{equation}
  r = \frac{\sum_{i=1}^{n} (X_i - \bar{X})(Y_i - \bar{Y})}{\sqrt{\sum_{i=1}^{n}(X_i - \bar{X})^2 \sum_{i=1}^{n}(Y_i - \bar{Y})^2}}
\end{equation}


- Do **not** use the Pearson Correlation coefficient if both variables are not quantitative. Instead, refer to the `mixed.cor()` from the [psch package](https://personality-project.org/r/psych/help/mixed.cor.html) to compute the correlations for mixtures of continuous, polytomous, and/or dichotomous variables.

- You should supplement any descriptive summaries with visualizations to ensure that you are able to interpret the computations correctly.


### A Synthetic Example: The Anscombe Dataset [1]

**In a seminal paper, Anscombe stated:**\footnotemark  \textit{Few of us escape being indoctrinated with these notions} 

- *numerical calculations are exact, but graphs are rough;*  
- *for any particular kind of statistical data there is just one set of calculations constituting a correct statistical analysis;*  
- *performing intricate calculations is virtuous, whereas actually looking at the data is cheating.*

**He proceeded by stating that** *a computer should make both calculations and graphs. Both sorts of output should be studied; each will contribute to understanding.*  

**Now, let us consider his four datasets, each consisting of eleven (x,y) pairs.**

\footnotetext{Anscombe, Francis J. 1973. ``Graphs in Statistical Analysis." \textit{The American Statistician} 27 (1): 17â€“21. (\href{https://www.sjsu.edu/faculty/gerstman/StatPrimer/anscombe1973.pdf}{Click here to access the full paper}).}

### A Synthetic Example: The Anscombe Dataset [2]
```{r anscombe2, echo=FALSE, results="asis"}
print(xtable(anscombe, align = c(rep('r', 9))), comment = FALSE, size = '\\normalsize', include.rownames=FALSE)
```

### A Synthetic Example: The Anscombe Dataset [3]
```{r anscombe3, echo = FALSE, results='asis'}
pacman::p_load(Tmisc) # same data but in 3 columns
df = quartet %>% group_by(set) %>% 
  summarise(x.mean = mean(x), x.sd = sd(x),
            y.mean = mean(y), y.sd = sd(y),
            corr = cor(x, y))
print(xtable(df, align = c(rep('c', 7))), comment = FALSE, size = '\\normalsize', include.rownames=FALSE)
```


### A Synthetic Example: The Anscombe Dataset [4]
```{r anscombe4, results='asis', echo=FALSE}
ggplot(quartet, aes(x, y)) + geom_point() + 
  geom_smooth(method = lm, se = FALSE) + facet_wrap(~set) + theme_bw()
```


### Anscombe-Like Mistakes in Research and Practice
In my estimation, Figure 8c represents an example where regression should not have been performed\footnotemark. 

\vspace{-\baselineskip}

\centering \href{https://www.jneurosci.org/content/32/11/3791/tab-figures-data}{\includegraphics[width=\textwidth, height=0.6\textheight, keepaspectratio,frame]{Figures/F8Large.jpg}}

\footnotetext{Cai, Xinying, and Camillo Padoa-Schioppa. 2012. ``Neuronal Encoding of Subjective Value in Dorsal and Ventral Anterior Cingulate Cortex.'' \textit{Journal of Neuroscience} 32(11):3791â€“3808.}



# Transformations

### First Differences

The change in the time series from one period to the next is known as the (first) difference. It can be computed as follows:
\begin{equation}
DY_t = Y_t - Y_{t-1}
\end{equation}

```{r djIndexDiff, echo=FALSE}
dowJonesIndex = tq_get("^DJI", from = "2021-01-25", to = "2021-01-30") %>% 
  select(symbol, date, adjusted)
dowJonesIndex$`Yt-1` = lag(dowJonesIndex$adjusted)
dowJonesIndex$DYt = dowJonesIndex$adjusted - dowJonesIndex$`Yt-1`
```

```{r djIndexDiff2, results="asis", echo=FALSE}
dowJonesIndex$date = as.character(dowJonesIndex$date)
print(xtable(dowJonesIndex, align = c(rep('c', 6))), comment = FALSE, size = '\\scriptsize', include.rownames=FALSE) 
```

Differences can be computed in one step using `diff()` from base R as follows.

```{r djIndexDiff3, echo=FALSE}
dowJonesIndex = tq_get("^DJI", from = "2021-01-25", to = "2021-01-30") %>% 
  select(symbol, date, adjusted)
dowJonesIndex$DYt = c(NA, diff(dowJonesIndex$adjusted))
```

```{r djIndexDiff4, echo=FALSE, results="asis"}
dowJonesIndex$date = as.character(dowJonesIndex$date)
print(xtable(dowJonesIndex, align = c(rep('c', 5))), comment = FALSE, size = '\\scriptsize', include.rownames=FALSE)

```

### Differencing for Seasonal Data {.allowframebreaks}

Recall the plot of the [Advance Retail Sales: Clothing and Clothing Accessory Stores (RSCCASN) FRED dataset](https://fred.stlouisfed.org/series/RSCCASN).

```{r fred}
pacman::p_load(tidyquant)
retailSales = tq_get("RSCCASN", get = "economic.data",
                     from = "2015-01-01", to = "2019-12-31")
retailSales$month = month(retailSales$date)
retailSales$year = year(retailSales$date) %>% factor()
retailSales %>% 
  ggplot(aes(x = month, y = price, color = year)) + geom_line() +
  labs(title = "How would you difference based on that plot?",
       x = "Month", y = "Sales in Millions of Dollars",
       caption = "Data from FRED, extracted using the tidyquant package") +
  scale_x_discrete() + scale_color_brewer(type = "qual") + theme_bw()
```

### Differencing with Seasonal Data [3]

**The table below is the result of Approach #1 in R**

```{r fred2, results="asis", echo=FALSE}
retailSales$`Yt-m` = lag(retailSales$price, 12)
retailSales$`DYt-m` = retailSales$price - retailSales$`Yt-m`
df = retailSales %>% select(-c(month, year, symbol)) %>% 
  mutate(date = as.character(date))
print(xtable(df[1:18,], align = c(rep('c', 5))), comment = FALSE, size = '\\scriptsize', include.rownames=FALSE)
```

### Differencing with Seasonal Data [4]

**The table below is the result of Approach #2 in R**

```{r fred3, echo=FALSE, results="asis"}
pacman::p_load(magrittr)
df %<>% select(-c(`Yt-m`, `DYt-m`))
df$`DYt-m` = c(rep(NA,12), diff(df$price, 12))
print(xtable(df[1:18,], align = c(rep('c', 4))), comment = FALSE, size = '\\scriptsize', include.rownames=FALSE)
```


### Growth Rates: The Formulation

In the absence of seasonality, the growth rate for a time series is given by
\begin{equation}
  GY_t = 100 \frac{Y_t - Y_{t-1}}{Y_{t-1}}
\end{equation}

In the presence of seasonality (with period $= m$), the growth rate for a time series is given by
\begin{equation}
  GY_t = 100 \frac{Y_t - Y_{t-m}}{Y_{t-m}}
\end{equation}


### Growth Rates in Practice -- a Non-Graded Class Activity

- **Question 1:** Let us say that an investor purchased 10 stocks of \$GME, on 2021-01-29, at \$325/stock. The next trading day, 2021-02-01, the \$GME stock closed at \$225. Compute the growth rate in their portfolio worth (assuming it only has the GME stock) over this time period. 

- Let us say that the growth rate, $GY_t = -g$. Now let us assume that the \$GME stock went up by $g$ (i.e., if it went down 10\%, it increased by 10\% over the next trading day).  What is the value of the investor's portfolio by stock market closing on 2021-02-02?

  - Provide the answer to both computational questions on [Canvas](https://miamioh.instructure.com/courses/142177/quizzes/368225).


### The Log Transform [1]

The log transformation can be computed as follows:
\begin{equation}
  L_t = \ln{(Y_t)}
\end{equation}
Note that the `log()` in R takes the natural logarithm as its default base, i.e., would transform a variable/statistic based on the above equation.

The reverse transformation using the exponential function is:
\begin{equation}
  e^{L_t} = e^{\ln{(Y_t})} = Y_t
\end{equation}

The first difference in logarithms represents the logarithm of the ratio:
\begin{equation}
  L_t = \ln{(\frac{Y_t}{Y_{t-1}})} = \ln{(Y_t)} - \ln{(Y_{t-1})}
\end{equation}


### The Log Transform [2]

- The primary purpose of the log transform is to **convert exponential growth into linear growth.**

- The transform often has the **secondary purpose of balancing the variance.**  

- Difference in logs and growth rate transformations produce similar results and interpretations.


### Plots with and without the Log Transformation [1]

```{r gdpPlot1, echo=FALSE}
gdp = read.csv("https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1168&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=GDP&scale=left&cosd=1947-01-01&coed=2020-10-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Quarterly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2021-02-02&revision_date=2021-02-02&nd=1947-01-01")
gdp$DATE = ymd(gdp$DATE)

gdp %>% 
  ggplot(aes(x = DATE, y = GDP)) + 
  geom_line() +
  labs(title = "GDP without Log Transformation",
       x = "Date", y = "GDP",
       caption = "Data from FRED") +
  scale_x_date(breaks = scales::pretty_breaks(10)) + theme_bw()
```

### Plots with and without the Log Transformation [2]

```{r gdpPlot2, echo=FALSE}
gdp$GDP = log(gdp$GDP)
gdp %>% 
  ggplot(aes(x = DATE, y = GDP)) + 
  geom_line() +
  labs(title = "GDP with Log Transformation",
       x = "Date", y = "Ln(GDP)",
       caption = "Data from FRED") +
  scale_x_date(breaks = scales::pretty_breaks(10)) + theme_bw() + ylim(c(5,10))
```

### Plots with and without the Log Transformation [3]

```{r gdpPlot3, echo=FALSE}
gdp = read.csv("https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1168&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=GDP&scale=left&cosd=1947-01-01&coed=2020-10-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Quarterly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2021-02-02&revision_date=2021-02-02&nd=1947-01-01")
gdp$DATE = ymd(gdp$DATE)
gdp$GDP = log(gdp$GDP)
gdp$GDP = c(rep(NA, 4), diff(gdp$GDP, 4))
gdp %>% na.omit() %>% 
  ggplot(aes(x = DATE, y = GDP)) + 
  geom_line() +
  labs(title = "Differences, with lag = 4, of the Log GDP",
       x = "Date", y = "DL(GDP)",
       caption = "Data from FRED") +
  scale_x_date(breaks = scales::pretty_breaks(10)) + theme_bw()
```


# Recap

### Summary of Main Points

\begin{block}{\textbf{Main Learning Outcomes}}
  \begin{itemize}
			\item \textbf{Use numerical summaries to describe a time series.} \\
			\item \textbf{Apply transformations to a time series.}
	\end{itemize}
\end{block}


### Things to Do

 - **Recommended:** Thoroughly read Chapter 2.1-2.6 of our book.  
 
 - Go through the slides, examples and make sure you have a good understanding of what we have covered.  
 
 - **Highly Recommended:** Go through the [Week 02 Self-Paced Study Guide](http://rstudio.fsb.miamioh.edu:3838/megahefm/isa444/week02/).  
 
 - **Required:** Complete the [graded assignment](https://miamioh.instructure.com/courses/142177/quizzes/368227).
 

### Graded Assignment 04: Evaluating your Understanding

Please go to \href{https://miamioh.instructure.com/courses/142177/quizzes/368227}{Canvas (click here)} and answer the four questions. **Due February 08, 2021 [11:40 AM, Ohio local time].** 

**What/Why/Prep?** The purpose of this assignment is to evaluate your understanding and retention of the material covered up to the end of Class 04. To reinforce your understanding of the covered material, I also suggest reading up to and including Chapter 2.6 of the book.

**General Guidelines:**  

\vspace{-0.5\baselineskip}

  - Individual assignment.  
  - This is **NOT** a timed assignment.    
  - Proctorio is NOT required for this assignment.  
  - You will need to have R installed (or accessible through the \href{https://virtualpc.fsb.miamioh.edu/RDWeb/Pages/en-US/default.aspx}{Remote Desktop})


---

\maketitle