---
title: "ISA 444: Business Forecasting"
subtitle: "05 - Basic Tools and Goodness of Fit (Cont.)"
author: Fadel M. Megahed
date: 'Fall 2020'
output:
  beamer_presentation:
    number_sections: false
    toc: false
    slide_level: 3
    includes: 
      in_header: structure.txt
classoption: "aspectratio=169"
always_allow_html: yes
bibliography: refs.bib
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      verbose = FALSE,
                      progress = FALSE,
                      fig.align = "center",
                      fig.pos = 'p',
                      fig.width = 5.8,
                      fig.height= 2.9,
                      allowframebreaks = TRUE,
                      fig.margin=TRUE,
                      kable.force.latex = TRUE,
                      cache = TRUE)
options(kableExtra.latex.load_packages = FALSE)
pacman::p_load(kableExtra, tidyverse, tidyquant, xtable)
```

# Preface


### Quick Refresher based on Last Class

\begin{block}{\textbf{Main Learning Outcomes}}
	 $\quad$ \textcolor{darkgreen}{\large \checkboxFadel}	\textbf{Use numerical summaries to describe a time series.} \\
	 $\quad$ \textcolor{miamired}{\large $\boxtimes$}	\textbf{Apply transformations to a time series.}
\end{block}



### Recap: Numerical Summaries

\begin{figure}
		\centering
		\fbox{%
			\begin{forest}
				[\LARGE{\textbf{Numercial Summaries}}
				[\textbf{Measures of Average}
				[Mean]
				[Median]]
				[\textbf{Measures of Variation}
				[Range]
				[Deviation]
				[MAD]
				[Variance]]
				[\textbf{Correlation}
				[Pearson]]]
		\end{forest}}
		\caption{An overview of the numerical summaries discussed last class.}
	\end{figure}


### Recap: Numerical Summaries do NOT Replace Visuals [1]

```{r anscombe2, echo=FALSE, results="asis"}
print(xtable(anscombe, align = c(rep('r', 9))), comment = FALSE, size = '\\scriptsize', include.rownames=FALSE)
```

### Recap: Numerical Summaries do NOT Replace Visuals [2]
```{r anscombe3, echo = FALSE, results='asis'}
pacman::p_load(tidyverse, tidyquant, Tmisc, xtable) # same data but in 3 columns
df = quartet %>% group_by(set) %>% 
  summarise(x.mean = mean(x), x.sd = sd(x),
            y.mean = mean(y), y.sd = sd(y),
            corr = cor(x, y))
print(xtable(df, align = c(rep('c', 7))), comment = FALSE, size = '\\scriptsize', include.rownames=FALSE)
```


### Recap: Numerical Summaries do NOT Replace Visuals [3]
```{r anscombe4, results='asis', echo=FALSE}
ggplot(quartet, aes(x, y)) + geom_point() + 
  geom_smooth(method = lm, se = FALSE) + facet_wrap(~set) + theme_bw()
```


### Recap: First Differences {.allowframebreaks}

The change in the time series from one period to the next is known as the (first) difference. It can be computed as follows:
\begin{equation}
DY_t = Y_t - Y_{t-1}
\end{equation}

```{r djIndexDiff}
dowJonesIndex = tq_get("^DJI", from = "2020-08-17", to = "2020-08-22") %>% 
  select(symbol, date, adjusted)
dowJonesIndex$`Yt-1` = lag(dowJonesIndex$adjusted)
dowJonesIndex$DYt = dowJonesIndex$adjusted - dowJonesIndex$`Yt-1`
```

```{r djIndexDiff2, results="asis", echo=FALSE}
dowJonesIndex$date = as.character(dowJonesIndex$date)
print(xtable(dowJonesIndex, align = c(rep('c', 6))), comment = FALSE, size = '\\scriptsize', include.rownames=FALSE) 
```

Note that the differences can be computed in one step using the function `diff()` from base R as follows.

```{r djIndexDiff3}
dowJonesIndex = tq_get("^DJI", from = "2020-08-17", to = "2020-08-22") %>% 
  select(symbol, date, adjusted)
dowJonesIndex$DYt = c(NA, diff(dowJonesIndex$adjusted))
```

```{r djIndexDiff4, echo=FALSE, results="asis"}
dowJonesIndex$date = as.character(dowJonesIndex$date)
print(xtable(dowJonesIndex, align = c(rep('c', 5))), comment = FALSE, size = '\\scriptsize', include.rownames=FALSE)
```


### Recap: Growth Rates in Practice -- a Non-Graded Class Activity

- **Follow up question:** Hypothetically speaking let us say that Fadel has purchased \$10 worth of [Stellar ($XLM)](https://coinmarketcap.com/all/views/all/). Each \$XLM coin was worth $0.1$ on 08-25-2020.  
  - Let us say that Fadel was lucky and his investment went up 20\% on 08-26-2020, i.e. $GY_t = 20$. Using the formula, compute the value of each coin on 08-26-2020. 

  - Due to the volatility of cryptocurrencies, let us assume that Fadel's growth rate for the following day was -20% (i.e., in comparison with the coin's value on 08-26-2020). Compute the value of the coin on 08-27-2020.

  - **Recall:**  
    
    - *Value of coin on 08-26-2020:* 0.12.   
    - *Value of coin on 08-27-2020:* 0.096.


### Learning Objectives for Today's Class

\begin{block}{\textbf{Main Learning Outcomes}}
  \begin{itemize}
			\item \textbf{Apply (log) transformations to a time series.}
			\item \textbf{Apply and interpret measures of forecast accuracy.}
			\item \textbf{Interpret prediction intervals for a simple forecast.}
	\end{itemize}
\end{block}



# Transformations

### The Log Transform [1]

The log transformation can be computed as follows:
\begin{equation}
  L_t = \ln{(Y_t)}
\end{equation}
Note that the `log()` in R takes the natural logarithm as its default base, i.e., would transform a variable/statistic based on the above equation.

The reverse transformation using the exponential function is:
\begin{equation}
  e^{L_t} = e^{\ln{(Y_t})} = Y_t
\end{equation}

The first difference in logarithms represents the logarithm of the ratio:
\begin{equation}
  L_t = \ln{(\frac{Y_t}{Y_{t-1}})} = \ln{(Y_t)} - \ln{(Y_{t-1})}
\end{equation}


### The Log Transform [2]

- The primary purpose of the log transform is to **convert exponential growth into linear growth.**

- The transform often has the **secondary purpose of balancing the variance.**  

- Difference in logs and growth rate transformations produce similar results and interpretations.


### Plots with and without the Log Transformation [1]

```{r gdpPlot1, echo=FALSE}
gdp = read.csv("https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1168&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=GDP&scale=left&cosd=1947-01-01&coed=2020-04-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Quarterly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2020-08-26&revision_date=2020-08-26&nd=1947-01-01")
gdp$DATE = ymd(gdp$DATE)

gdp %>% 
  ggplot(aes(x = DATE, y = GDP)) + 
  geom_line() +
  labs(title = "GDP without Log Transformation",
       x = "Date", y = "GDP",
       caption = "Data from FRED") +
  scale_x_date() + theme_bw()
```

### Plots with and without the Log Transformation [2]

```{r gdpPlot2, echo=FALSE}
gdp$GDP = log(gdp$GDP)
gdp %>% 
  ggplot(aes(x = DATE, y = GDP)) + 
  geom_line() +
  labs(title = "GDP with Log Transformation",
       x = "Date", y = "Ln(GDP)",
       caption = "Data from FRED") +
  scale_x_date() + theme_bw() + ylim(c(5,10))
```

### Plots with and without the Log Transformation [3]

```{r gdpPlot3, echo=FALSE}
gdp = read.csv("https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1168&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=GDP&scale=left&cosd=1947-01-01&coed=2020-04-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Quarterly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2020-08-26&revision_date=2020-08-26&nd=1947-01-01")
gdp$DATE = ymd(gdp$DATE)
gdp$GDP = log(gdp$GDP)
gdp$GDP = c(rep(NA, 4), diff(gdp$GDP, 4))
gdp %>% na.omit() %>% 
  ggplot(aes(x = DATE, y = GDP)) + 
  geom_line() +
  labs(title = "Differences, with lag = 4, of the Log GDP",
       x = "Date", y = "DL(GDP)",
       caption = "Data from FRED") +
  scale_x_date() + theme_bw()
```


# Measures of Forecast Accuracy

### Recap: Definition of Forecast

\begin{figure}
  \centering
  \href{https://tinyurl.com/y5h5k4aj}{\includegraphics[width=0.9\textwidth, height = 0.7\textheight, frame, keepaspectratio]{Figures/forecastDef.png}}
  \caption{The definition of the term "forecast" as obtained from Bing/Merriam-Webster.}
\end{figure}


### A Naive Forecast

- A naïve forecast for an observation, $Y_t$ , is the observation prior, $Y_{t-1}$.  

- For some types of time series (e.g. Random Walks), a naïve forecast is
the best possible forecast one can make\footnotemark.

- In the case of seasonal data, a naïve forecast could be the observation
from the prior period.   
  - For example, in the case of monthly data, the naïve forecast for the observation $Y_{Jan 2018}$ could be $Y_{Jan 2017}$. In this case, we would denote the frequency, m=12, and the naïve forecast for $Y_t$ is the observation $m$ periods prior, or $Y_{t-m}$.

\footnotetext{Slide is from \href{https://miamioh.edu/fsb/directory/?up=/directory/farmerl2}{Dr. Allison Jones-Farmer's} lecture notes, Miami University, Spring 2020.}


### Measures of Forecast Accuracy

The measures of accuracy we will discuss all deal with the difference
between the actual observed value ($Y_t$) and the forecasted value ($F_t$) at
time $t$. In order to measure forecast accuracy, we assume we have $m$ actual
values available, thus we have $Y_{t+1}, \, Y_{t+2}, \, \dots, \, Y_{t+m}$ and forecasts $F_{t+1}, \, F_{t+2}, \, \dots, \, F_{t+m}$. This is important because we will be averaging the forecast errors over $m$.\footnotemark

\footnotetext{Note that your textbook discusses rolling forecast origins. This is important, but we will save this discussion for later in the semester. For now, assume the forecast origin is fixed (i.e., we are only interested in the one-period ahead forecast).}


**Forecast Error:** 
\begin{equation}
  e_{t+i} = Y_{t+i} - F_{t+i}.
\end{equation}

### Measures Reflecting "Average" Forecast Performance

**Mean Error:** 
\begin{equation}
  ME = \frac{\sum_{i=1}^{m} e_{t+i}}{m}.
\end{equation}

**Mean Percentage Error:** 
\begin{equation}
MPE = \frac{100}{m}\sum_{i=1}^{m}\frac{ e_{t+i}}{Y_{t+i}}.
\end{equation}


### Computing Measures of "Average" Forecast Performance {.allowframebreaks}

```{r meanError1, echo=FALSE, results="asis"}
pacman::p_load(tidyquant, magrittr)
aapl = tq_get("AAPL", from = "2020-08-17", to = "2020-08-29") %>% 
  select(symbol, date, adjusted)
aapl %<>% mutate(naiveFC = lag(adjusted),
                 e = adjusted - naiveFC,
                 PE = 100*e/adjusted)
aapl$date %<>%  as.character()
print(xtable(aapl, align = c(rep('c', 7))), comment = FALSE, size = '\\scriptsize', include.rownames=FALSE)
cat(paste0("Based on Approach #1, the ME and MPE are equal to ", mean(aapl$e, na.rm = T) %>% round(2), " and ", mean(aapl$PE, na.rm = T) %>% round(2),
           "% , respectively."))
```

**Comments:**     

  - We are forecasting the adjusted closing price of the AAPL stock for the next trading day, i.e., we are ignoring non-trading days.  
  - The naïve forcast is the `lag(1)` of the series; thus, the forecast error is the `diff(1)`.
  
```{r meanError2, results="asis"}
pacman::p_load(tidyquant, magrittr, fpp2)

aapl = tq_get("AAPL", from = "2020-08-17", to = "2020-08-29") %>% 
  select(symbol, date, adjusted)
naiveFC = snaive(aapl$adjusted) %>% .[['fitted']] #snaive from fpp2

e = aapl$adjusted - naiveFC
ME = mean(e, na.rm = T)
MPE = 100*mean(e/aapl$adjusted, na.rm = T)

cat(paste0("Based on Approach #2, the ME and MPE are equal to ", round(ME, 2), " and ", round(MPE, 2),
           "%, respectively."))
```


### Measures Reflecting "Variablity" in Forecast Performance

**Absolute Forecast Error:** 
\begin{equation}
  |e_{t+i}| = |Y_{t+i} - F_{t+i}|.
\end{equation}

**Squared Forecast Error:** 
\begin{equation}
  (e_{t+i})^2 = (Y_{t+i} - F_{t+i})^2.
\end{equation}

**Mean Absolute Error:** 
\begin{equation}
MAE = \frac{\sum_{i=1}^{m}|e_{t+i}|}{m}.
\end{equation}


**Root Mean Squared Error:** 
\begin{equation}
RMSE = \sqrt{\frac{\sum_{i=1}^{m}(e_{t+i}^2}{m}}.
\end{equation}


### Measures Reflecting "Relative" Forecast Performance

**Mean Absolute Percentage Error:** 
\begin{equation}
MAPE = \frac{100}{m} \sum_{i=1}^{m} \frac{|e_{t+i}|}{m}.
\end{equation}

**Relative Mean Absolute Error:**
\begin{equation}
RelMAE = \frac{\sum_{i=1}^{m}|e_{t+i}|}{\sum_{i=1}^{m} |Y_{t+i} - Y_{t+i-1}|}.
\end{equation}

**Thiel's U:**
\begin{equation}
U = \sqrt{ \frac{\sum_{i=1}^{m}(e_{t+i})^2}{\sum_{i=1}^{m} (Y_{t+i} - Y_{t+i-1})^2} }.
\end{equation}


### An Overview of Computing these Measures in R {.allowframebreaks}

```{r computations1}
pacman::p_load(tidyquant, magrittr, fpp2, xtable)

aapl = tq_get("AAPL", from = "2020-08-17", to = "2020-08-29") %>% 
  select(symbol, date, adjusted)
naiveFC = lag(aapl$adjusted)

e = aapl$adjusted - naiveFC
ME = mean(e, na.rm=T)
RMSE = mean(e^2, na.rm=T) %>% sqrt()
MAE = abs(e) %>% mean(na.rm=T)
MPE = 100 * mean(e/aapl$adjusted, na.rm=T)
MAPE= 100 * mean(abs(e)/aapl$adjusted, na.rm=T)
```


```{r computations2}
E = c(ME, RMSE, MAE, MPE, MAPE)
names(E) = c("ME", "RMSE", "MAE", "MPE", "MAPE")
round(E, 2) %>% print()

# Alternatively, we could have just computed it using the fpp2 package
accuracy(naiveFC, aapl$adjusted) %>% round(2)
```


# Prediction Intervals

### Point vs Interval Forecasts

- **Point Forecasts:** future observations for which we report a single forecast observation.  

- **Interval Forecast:** a range of values that are reported to forecast an outcome.


If we assume the forecast errors follow a Normal Distribution, an approximate $100(1-\alpha)$ prediction interval can be computed as follows:  
\begin{equation}
  \hat{F}_t \pm Z*RMSE,
\end{equation}
where:  

- $\hat{F}_t$ forecast at time $t$.  
- The RMSE can be used as an estimate of the standard deviation of the forecast errors.  
- $Z$ is the quantile corresponding to $100(1-\frac{\alpha}{2})$.


### Recall: Standard Normal Distribution [1]

```{r normPlot, echo=FALSE}
x = seq(-3.75,3.75,0.001)
dist = dnorm(x)
probs = seq(0, 1, 0.001)
ggplot(data.frame(x = x, d = dist),
       aes(x = x, y = d)) + geom_line() + theme_bw() +
  labs(title = "Standard Normal Density Function",
       x = "Z", y = "Density")
```

### Recall: Standard Normal Distribution [2]

```{r normPlot2, echo=FALSE}
p = ggplot(data.frame(x = probs, inverseCDF = qnorm(probs)),
       aes(x = x, y = inverseCDF)) + geom_line() + theme_bw() +
  labs(title = "Quantile / inverse CDF of Standard Normal Dist.",
       y = "Z", x = "Probability") +
  geom_vline(xintercept = 0.975, color = "red", size = 1.15) +
  geom_hline(yintercept = qnorm(0.975), color = "red", size = 1.15)
p + annotate("text", x = 0.64, y = 2.3, label = "Z value is approximately 1.96 for prob = 0.975", color = "red")
```


### Prediction Intervals for the $AAPL Data {.allowframebreaks}

```{r pIs}
PInormU = naiveFC + abs(qnorm(0.975))*RMSE
PInormL = naiveFC - abs(qnorm(0.975))*RMSE
dfNaive = data.frame(date = aapl$date, Ft = naiveFC, PInormU, PInormL)
dfNaive %>% ggplot(aes(x= date, y = naiveFC)) + geom_line() +
  theme_bw() + 
  labs(title ="Overlaying 95% Prediction Intervals in ggplot",
       fill = "95% PI") +
    geom_ribbon(aes(ymin = PInormL , ymax = PInormU, fill = "band"), 
              alpha = 0.2, color = "red") + 
  theme(legend.position= "bottom")
```

# Recap

### Summary of Main Points

\begin{block}{\textbf{Main Learning Outcomes}}
  \begin{itemize}
			\item \textbf{Apply (log) transformations to a time series.}
			\item \textbf{Apply and interpret measures of forecast accuracy.}
			\item \textbf{Interpret prediction intervals for a simple forecast.}
	\end{itemize}
\end{block}


### Things to Do

 - Thoroughly read all of Chapter 2 of our book.
 
 - Go through the slides, examples and make sure you have a good understanding of what we have covered. 
 
 - Recreate the plots in Slides 15-17 for the [RSCCASN Data](https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1168&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=RSCCASN&scale=left&cosd=1992-01-01&coed=2020-07-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2020-08-30&revision_date=2020-08-30&nd=1992-01-01). Note that the period, $m=12$.
 
 - If you are interested in additional practice problems, please consider the following problems from your textbook. To access these datasets, please click [here](https://www.wessexlearning.org/pobf2e/index.html).
   - For the Means approaches in Example 2.7 (P.49), use R to compute the 7 error measures for the four forecasting approaches.  
   - Exercise 2.12 and compute the forecast errors for the naive forecast. 
  
  
### Graded Assignment 04: Evaluating your Retention/Focus
Please go to \href{https://miamioh.instructure.com/courses/123532/quizzes/321567}{Canvas (click here)} and answer the questions. **Due Sept. 3, 2020 [2:50 PM,
Ohio local time].** 

**What/Why/Prep?** The purpose of this assignment is to evaluate your understanding and retention of the material covered up to the end of Class 04. In order to prepare for this, you should have either actively attended class and/or watched the recording from WebEx. Furthermore, you should have thoroughly read up to the end of Chapter 2 from your textbook.

**General Guidelines:**  

\vspace{-0.5\baselineskip}

  - Individual assignment.  
  - This is **NOT** a timed assignment (i.e. once you start the assignment you will have 10-15 minutes to complete the one question).  
  - Proctorio is NOT required for this assignment.  
  - You will need to have R installed (or accessible through the \href{https://virtualpc.fsb.miamioh.edu/RDWeb/Pages/en-US/default.aspx}{Remote Desktop})

### Graded Assignment 05: Evaluating your Retention/Focus
Please go to \href{https://miamioh.instructure.com/courses/123532/quizzes/322517}{Canvas (click here)} and answer the two questions. **Due Sept. 7, 2020 [2:50 PM,
Ohio local time].** 

**What/Why/Prep?** The purpose of this assignment is to evaluate your understanding and retention of the material covered up to the end of Class 05. In order to prepare for this, you should have either actively attended class and/or watched the recording from WebEx. Furthermore, you should have thoroughly read up to the end of Chapter 2 from your textbook.

**General Guidelines:**  

\vspace{-0.5\baselineskip}

  - Individual assignment.  
  - This is **NOT** a timed assignment (i.e. once you start the assignment you will have 10-15 minutes to complete the one question).  
  - Proctorio is NOT required for this assignment.  
  - You will need to have R installed (or accessible through the \href{https://virtualpc.fsb.miamioh.edu/RDWeb/Pages/en-US/default.aspx}{Remote Desktop})


```{r electricity, echo=FALSE, eval=FALSE}
pacman::p_load(readxl, tidyverse)
download.file("https://www.wessexlearning.org/pobf2e/dsa/Electricity.xlsx",
              destfile = "Data/Electricity.xlsx", mode = "wb")

upperPI = 740 + qnorm((1 - 0.9)/2)*318.3
```

---

\maketitle