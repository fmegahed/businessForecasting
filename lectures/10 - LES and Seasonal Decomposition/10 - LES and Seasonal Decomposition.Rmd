---
title: "ISA 444: Business Forecasting"
subtitle: "10 - LES and Seasonal Decomposition"
author: Fadel M. Megahed
date: 'Spring 2021'
output:
  beamer_presentation:
    number_sections: false
    toc: false
    slide_level: 3
    includes: 
      in_header: structure.txt
classoption: "aspectratio=169"
always_allow_html: yes
bibliography: refs.bib
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      verbose = FALSE,
                      progress = FALSE,
                      fig.align = "center",
                      fig.pos = 'p',
                      fig.width = 5.95,
                      fig.height= 2.5,
                      allowframebreaks = TRUE,
                      fig.margin=TRUE,
                      kable.force.latex = TRUE,
                      cache = FALSE)
options(kableExtra.latex.load_packages = FALSE)
pacman::p_load(kableExtra, xtable, tidyverse, magrittr, tidyquant, fpp2, ggpubr, scales, sweep)
```

# Preface

### What we Covered Last Week

\begin{block}{\textbf{Main Learning Outcomes}}
			$\quad$ \textcolor{darkgreen}{\large \checkboxFadel} \textbf{Recognize time series that are appropriate for simple exponential smoothing (SES).} \\
			$\quad$ \textcolor{darkgreen}{\large \checkboxFadel} \textbf{Use SES to smooth past observations of a time series.} \\
			$\quad$ \textcolor{darkgreen}{\large \checkboxFadel} \textbf{Use SES to forecast future observations of a time series.} \\
			$\quad$ \textcolor{darkgreen}{\large \checkboxFadel} \textbf{Compare the forecasting performance of SES to other suitable techniques (i.e., methods that require similar assumptions).} \\
			$\quad$ \textcolor{darkgreen}{\large \checkboxFadel} \textbf{Recognize time series that are appropriate for linear exponential smoothing (LES).} \\
			$\quad$ \textcolor{miamired}{\large $\boxtimes$} \textbf{Use LES to forecast future observations of a time series.}
\end{block}

### Recap: A 10,000 Foot View of Forecasting Methods

\vspace{\baselineskip}

\begin{figure}
		\centering
		\adjustbox{max width=\textwidth, frame}{%
			\begin{forest}
				[\large{\textbf{Forecasting}}
				[\textbf{Judgemental}
				[Sales Composite]
				[Customer Survey]
				[Delphi Method]]
				[\textbf{Quantitative}
				[\textcolor{miamired}{\textbf{Extrapolative}}
				[\textcolor{darkgreen}{\textbf{Naive}}]
				[\textbf{Smoothing-based}
				[\textcolor{darkgreen}{\textbf{$\approx$Stationary}}
				[Average]
				[MA]
				[SES]]
				[\textcolor{darkgreen}{\textbf{Trend}}
				[\textcolor{orange}{Holt's}]]
				[\textcolor{darkgreen}{\textbf{Both?}}
				[Holt-Winters]
				]]
				[\textbf{``Advanced''}
				[(S)ARIMA]
				[GARCH]]]
				[\textcolor{miamired}{\textbf{Causal}}
				[\textbf{Statistical}
				[(S)ARIMAX]]
				[\textbf{ML-Based}
				[\textcolor{darkgreen}{\textbf{Feature Eng.}}
				[e.g. AutoML]]]
				]
				]
				]
		\end{forest}}
		\caption{A 10,000 foot view of forecasting techniques\footnotemark}
\end{figure}

\footnotetext{An (incomplete) classification of forecasting techniques. Note that these focus on univariate time-series. Hence, they exclude popular approaches used in multivariate time series forecasting.}


### Learning Objectives for Today's Class
\begin{block}{\textbf{Main Learning Outcomes}}
  \begin{itemize}
			\item \textbf{Recognize time series that are appropriate for linear exponential smoothing (LES).}
			\item \textbf{Use LES to forecast future observations of a time series.}
			\item \textbf{Explain when to use an additive vs. multiplicative model for a time series.}
			\item \textbf{Use classic decomposition methods to detrend and deseasonalize a time series.}
	\end{itemize}
\end{block}


# Linear Exponential Smoothing (LES)

### Definition and Basic Principles {.allowframebreaks}

Linear Exponential Smoothing (LES) is a method used for one-step-ahead forecasting of a time series when there \textcolor{miamired}{is a local trend, but no} seasonal pattern.

A “global” trend occurs when a trend is increasing or decreasing at a nearly constant rate as in a simple linear regression model:
$$
y_t = \beta_0 + \beta_1t + \epsilon_t
$$

**A “local” trend occurs when a linear trend is increasing or decreasing at a nonconstant rate.** LES, also referred to as Holt’s Method or double exponential smoothing, is appropriate when the level ($\beta_0$) of the series is slowly changing as with SES, and the trend is also changing over time.

To compute the **forecast** we will use two smoothing constants, $\alpha$, to smooth the level, and $\beta$, the smoothing constant to smooth the trend.

The estimate of the **level** is: 
\begin{equation}
l_t = \alpha y_t + (1-\alpha)[l_{t-1} + b_{t-1}]
\end{equation}

The estimate of the **trend** is:
\begin{equation}
b_t = \beta [l_t - l_{t-1}] + (1-\beta) b_{t-1}
\end{equation}

To estimate the **point forecast** for time $t+h$ time periods ahead made in time $t$:
\begin{equation}
\hat{y}_{t+h}(t) = l_t + (h\times b_t)
\end{equation}


### What needs to be Determined/Optimized for? [1]

- Starting value for the level, $L_0$  and the starting value of the trend, $B_0$:  

  - When fitting “by hand” you can use a training sample and fit a simple linear trend regression, $\hat{y}_t = b_0 + b_1 t$, to obtain initial estimates of $L_0$ and $B_0$.  
  
  - $L_0 = b_0$, the intercept from a simple regression equation.  
  
  - $B_0 = b_1$, the slope from a simple regression equation.  
  

### What needs to be Determined/Optimized for? [2]

- The value of the smoothing constant for the level, $\alpha$, and the smoothing constant for the trend, $\beta$.\footnotemark  

  - $0 < \alpha < 1$, and $0 < \beta < 1$;  
  
  - The values for $\alpha$ and $\beta$ may be chosen to be the same or different, depending on the nature of the time series.  
  
  - Often the choices of the smoothing constants are arbitrary.  
  
  - $\alpha$ and $\beta$ can also be chosen by minimizing the mean squared one-step ahead forecast error (MSE) or equivalently, the square root of the mean squared one-step ahead forecast error (RMSE).

\footnotetext{The past four slides are adapted from \href{https://miamioh.edu/fsb/directory/?up=/directory/farmerl2}{Dr. Allison Jones-Farmer's Handouts} for ISA 444, Spring 2020.}

### Example 1: Weekly Thermometer Sales (Chart)

Below is a simple line plot based on ``Weekly_Therm_Sales.xlsx''. 

```{r thermSales, echo=FALSE, results='asis', fig.height=2.5}
thermSales = readxl::read_excel("Data/Weekly_Therm_Sales.xlsx")

thermSales %>% ggplot(aes(x = Time, y = WeeklyThermSales)) + 
  geom_line() + geom_point() + theme_bw()
```


### Example 1: Using R to Compute the Forecast [1]

**This is a live class demo, where we will use R to obtain the results shown in the next 3 slides.**

```{r holtTherm1, echo=FALSE, fig.height=2.35}
thermSales = readxl::read_excel("Data/Weekly_Therm_Sales.xlsx")
weeklySales = thermSales$WeeklyThermSales
les = holt(weeklySales, alpha = 0.2, beta = 0.1, h=10)
autoplot(les) + theme_bw()
```

### Example 1: Using R to Compute the Forecast [2]

```{r holtTherm2, echo=FALSE, results="asis"}
thermSales$Forecast = les$fitted
print(xtable(thermSales[1:9, ], align = c(rep('c', 4))), comment = FALSE, row.names = FALSE)
```

### Example 1: Using R to Compute the Forecast [3]
```{r holtTherm3, echo=FALSE, results="asis"}
print(xtable(accuracy(les), align = c(rep('c', 8)), digits = c(0, rep(3,7)) ), comment = FALSE)
```

### Optimizing the Smoothing Parameter: WFJ Sales Series
To illustrate the aforementioned concepts, let us examine the data for the [WFJ Sales Example](https://github.com/fmegahed/businessForecasting/raw/master/lectures/09%20-%20Forecasting%20Non-Seasonal%20Series/Data/WFJ_sales.xlsx) (i.e., Example 3.2 in our textbook). Per the textbook example, we will use the first the 26 observations as the estimation sample. **Note that we will now apply LES instead of the SES approach we examined last class.**

```{r wfjSalesLES}
pacman::p_load(readxl)
download.file("https://github.com/fmegahed/businessForecasting/blob/master/assignments/WFJ_sales.xlsx?raw=true", destfile = "Data/WFJ_sales.xlsx", mode = "wb")
WFJ = read_excel("Data/WFJ_sales.xlsx") %>% select(c(1,2))
```

**This example will be coded live in class to obtain the results below.**


```{r wfjSalesCompleteLES, echo=FALSE, results='asis'}
trainData = WFJ[1:26,] # using the first 26 observations for training
ntrain = nrow(trainData) # getting the sample size

les = holt(trainData$`WFJ Sales`, h = 36)
metrics = accuracy(les)
cat(paste0('The optimal alpha and beta obtained using R are equal to ', 
           round(les$model$par['alpha'], 3), ', and ', round(les$model$par['beta'], 3), ', respectively.'), '\n')
print(xtable(metrics, align = c(rep('c', 8)), digits = c(0, rep(3, 7)) ), comment = FALSE)
```

### The Validation Results: The Basics
**A continuation of the live coding session, where we: (a) examine the validation results; and (b) print the combined training and validation results in one table.**

```{r wfjSalesCompleteLES2, echo=FALSE, results='asis'}
lesValid =holt(WFJ$`WFJ Sales`, h =10, alpha = les$model$par['alpha'], beta = les$model$par['beta'])
WFJ$lesOpt = lesValid %>% .[['fitted']]
validationData = WFJ[27:62,]
validationMetrics = accuracy(validationData$`WFJ Sales`, validationData$lesOpt)

combinedMetrics = rbind(metrics[1, -c(6,7)], validationMetrics)
row.names(combinedMetrics) = c('Training Set', 'Validation Set')
print(xtable(combinedMetrics, align = c(rep('c', 6)), digits = c(0, rep(3, 5)) ), comment = FALSE)
```


### The Validation Results: Visually

```{r wfjSalesCompleteLES3, echo=FALSE}
autoplot(lesValid) + autolayer(fitted(lesValid), series = 'LES (optimal)') +
  theme_bw() + theme(legend.position = 'bottom') + 
  labs(x = 'Obs. Number', y = 'Weekly Sales')
```


### Applying a Smoothing Method to Many TS

In this activity, we will apply `holt()` on the log(adjusted) on the following data.

```{r multipleHolt}
crypto = tq_get(c('BTC-USD', 'ETH-USD', 'LTC-USD', 'ADA-USD', 
                  'LINK-USD', 'ZIL-USD'), from = '2020-10-15')
```


```{r multipleHoltSolution, fig.height=2.2, echo=FALSE}

crypto = tq_get(c('BTC-USD', 'ETH-USD', 'LTC-USD', 'ADA-USD', 
                  'LINK-USD', 'ZIL-USD'), from = '2020-10-15') %>% 
  select(c(symbol, date, adjusted))

crypto %<>% group_by(symbol) %>%
  mutate(adjustedLog = log(adjusted))

nestedCrypto = crypto %>% select(-c(date, adjusted)) %>% nest(data = adjustedLog)

nestedCrypto %<>% mutate(data.ts = map(.x = data, .f = ts, start = c(2020, yday('2020-10-15')), freq = 365),
                         fitHolt = map(.x = data.ts, .f = holt, h = 14, level = 95, alpha = 0.2, beta = 0.1),
                         acc = map(.x = fitHolt, .f = accuracy),
                         RMSE = map(.x = acc, .f = 2),
                         sweep = map(.x= fitHolt, .f = sw_sweep, fitted = TRUE, timetk_idx = FALSE))

unnestCrypto = nestedCrypto %>% unnest(sweep)  

unnestCrypto$index %<>% date_decimal()

cols <- c("actual" = 'black', "fitted" = 'gray', "forecast" = "red")

unnestCrypto %>% ggplot(aes(x = index, y = adjustedLog, group = symbol, color = key)) + geom_line() + 
  scale_color_manual(values = cols) +
  geom_ribbon(aes(ymin = lo.95, ymax = hi.95), color = NA, alpha = 0.1) +
  facet_wrap(~symbol, ncol = 2, scales = 'free_y') + theme_bw(base_size = 7) +
  theme(legend.position = 'top')
```



# Time Series Components

### Definition and Basic Principles [1]

A time series may be made up of:  

- **Trends (T)** - upward and downward movements  
- **Seasonal (S) components** - regular, recurrent patterns that repeat at a fixed known duration (period)  
- **Error (E) components** - irregular “noise” that is randomly distributed over time\footnotemark


\footnotetext{A time series may also contain a cyclical component if it displays a somewhat periodic fluctuation, but the fluctuation has a periodicity of unknown duration, usually longer than a year.}


### Definition and Basic Principles [2]

```{r decompose, echo=FALSE}
pacman::p_load(tidyverse, magrittr, fpp2)
df = co2
decomposed = decompose(df)
autoplot(decomposed) + theme_bw(base_size = 7) + labs(title = NULL, caption = 'Based on C02 data in base R')
```


### Recall: Additive vs. Multiplicative Models [1]

An additive model is written as $Y = T + S + E$. 

**Definition:** *An additive model is appropriate when the trend is approximately linear, and the seasonal components stays constant over time.*

```{r addPlot, fig.height=2, echo=FALSE}
pacman::p_load(lubridate)
retail = read.csv("https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1168&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=RSXFSN&scale=left&cosd=2011-01-01&coed=2019-12-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2020-09-28&revision_date=2020-09-28&nd=1992-01-01")
retail %>% ggplot(aes(x = ymd(DATE), y = RSXFSN)) +
  geom_line() + 
  labs(x=NULL,
       title = "Seasonality with an Additive Trend", 
       subtitle = "Retail (- Food Services) from 2011-01-01 to 2019-12-01",
       caption = 'Data from FRED') +
  theme_bw(base_size = 7)
```


### Recall: Additive vs. Multiplicative Models [2]

A fully multiplicative model is written as Y = TSE.

**Definition:** *It is appropriate when the rate of change in the trend and/or the seasonal component and/or the variability in the error term increase or decrease over time.*

```{r airpassengers, echo=FALSE, fig.height=2}
data("AirPassengers")
autoplot(AirPassengers) + 
  labs(x=NULL, title = "Seasonality with a Multiplicative Trend: Non-linear trend & seasonal component grows over time",
       caption = 'AirPassengers R Dataset -- Source: Box, G. E. P., Jenkins, G. M. and Reinsel, G. C. (1976) Time Series Analysis, Forecasting and Control.') +
  theme_bw(base_size = 7)
```


### Some Comments

- When the trend and seasonal component are multiplied together, larger levels in the series will tend to exhibit larger peaks and troughs. When the error term is also multiplicative, the magnitude of the forecast errors will tend to rise and fall with the level of the series.\footnotemark

- If the error variability is relatively constant over time, but the trend and/or seasonal components increase/decrease over time, a **mixed
additive/multiplicative model**, $Y = TS + E$, may be more appropriate.  

- An alternative to using a purely multiplicative model is to first transform the data using a logarithmic transformation.
$$
\begin{split}
Y & = TSE \\
\ln{(Y)} & = \ln{(TSE)} \\
 & = \ln{(T)} + \ln{(S)} + \ln{(E)}
\end{split}
$$

\footnotetext{Slide is from \href{https://miamioh.edu/fsb/directory/?up=/directory/farmerl2}{Dr. Allison Jones-Farmer's} lecture notes, Miami University, Spring 2020.}



# Decomposition Methods

### Background: Centered Moving Averages

Calculate the CMA(3), where you center the moving average in the middle of the moving window.

```{r bikeSalesTable, echo=FALSE, results='asis'}
bike = readxl::read_excel("Data/BikeSalesR.xlsx")
bike$MA3 = '----'
print(xtable(bike, align = c(rep('c', 4)) ), comment = FALSE, size = '\\scriptsize', 
      include.rownames=FALSE)

#Solution can be obtained using:
bike$MA3 = rollmean(bike$`Bike Sales`, k = 3, na.pad = TRUE, align = 'center') # from the zoo package
```

\textbf{\textcolor{miamired}{Question:} How do we handle the case when $k$ is even??}


### Decomposition Methods

Decomposition methods are used to “decompose” a time series into its components. Decomposition methods are generally poor forecasting methods, but they work well for:  

  - exploring and visualizing time series data  
  - detrending and/or deseasonalizing data  

Decomposition methods may be applied to multiplicative or additive time series.



### Pure Decomposition Process for an Additive Time Series

  - **Estimate the trend** by calculating the centered moving average for a window of width $K$, denoted as CMA($K$). Note you will lose $(K-1)/2$ observations at the beginning and end of the series if $K$ is odd;  suppose $K=3$, so we lose one observation at the beginning and the end.  
  
  - **Detrend the series** by subtracting the CMA from the corresponding observations.  
  
  - **Estimate the initial seasonal factors** by calculating the average value of the detrended series for each quarter, month, day, etc. (depending on the season length).  
  
  - **Standardize the seasonal factors** by computing their averages and then setting the final seasonal factor for each season equal to the initial value minus the overall average.  
  
  - **Estimate the error term** by subtracting seasonal factor from the detrended series for each corresponding season.


### Activity: Decomposing the BikeSalesR.xlsx

Based on the procedure described above, please use Excel/R to perform the aforementioned five steps.


### A Live Demo of Using R as an alternative

In class, we will use R to decompose the series and obtain the following plot

```{r bikeDecomposed, echo=FALSE, fig.height=2.4}
bike = bike %>% select(-c(MA3))
fit = ts(bike$`Bike Sales`, frequency = 4) %>% decompose()
autoplot(fit) + theme_bw(base_size = 7)
```

### Notes on the `decompose()` in R

  - The `decompose()` function in R uses a slightly different algorithm than your textbook presents.\footnotemark  
  
  - The MA used to compute the trend estimate is a $2 \times m$ moving average. This means that for quarterly data, a $2 \times 4$ moving average is computed. First a MA(4) is computed, then a MA(2) of the MA(4) is computed. This is used to estimate the trend.  
  
  - The seasonal components are computed as usual and centered.
  
\footnotetext{Slide is from \href{https://miamioh.edu/fsb/directory/?up=/directory/farmerl2}{Dr. Allison Jones-Farmer's} lecture notes, Miami University, Spring 2020.}
  

### Pure Decomposition Process for a Multiplicative Model

  - **Estimate the trend** by calculating the centered moving average for a window of width $K$ (i.e., CMA(K)).  For now, let us assume that $k=3$.
  
  - **Detrend the series** dividing the observations $2,..,(n-1)$ from the their corresponding CMA(3).  
  
  - **Estimate the initial seasonal factors** by calculating the average value of the detrended series for each quarter, month, day, etc. (depending on the season length).  
  
  - **Standardize the seasonal factor** by computing their averages and then setting the final seasonal factor for each season equal to the
initial value divided by the overall average.  

  - **Estimate the error term** by dividing the detrended series by the seasonal factor for each corresponding season.


### Limitations to Decomposition

  - Decomposition is widely used in practice but is not a good forecasting method.  

  - Decomposition methods are useful for visualizing your data and exploratory data analysis.  

  - Trend estimates are from moving averages and are not available for the first few and last few observations.  

  - Decomposition methods assume that the seasonal factors occur regularly from season to season over every period. This may not be true over the long run.  

  - Decomposition methods are not robust to unusual or spurious patterns that may occur in the data.  

Because of these limitations, we need a better forecasting method for seasonal data!\footnotemark

\footnotetext{Slide is from \href{https://miamioh.edu/fsb/directory/?up=/directory/farmerl2}{Dr. Allison Jones-Farmer's} lecture notes, Miami University, Spring 2020.}




# Recap

### Summary of Main Points
\begin{block}{\textbf{Main Learning Outcomes}}
  \begin{itemize}
			\item \textbf{Recognize time series that are appropriate for linear exponential smoothing (LES).}
			\item \textbf{Use LES to forecast future observations of a time series.}
			\item \textbf{Explain when to use an additive vs. multiplicative model for a time series.}
			\item \textbf{Use classic decomposition methods to detrend and deseasonalize a time series.}
	\end{itemize}
\end{block}

### Things to Do

 - **Recommended:** Thoroughly read Chapter 3.1-3.4 of our book.  
 
 - Go through the slides, examples and make sure you have a good understanding of what we have covered.  
 
 - **Highly Recommended:** Go through the [Week 04-05 Self-Paced Study Guide](rstudio.fsb.miamioh.edu:3838/megahefm/isa444/weeks04-05/).  

- **Required:** Complete the two graded assignments (see details in next slides).
 

### Graded Assignment 08: Evaluating your Understanding

Please go to \href{https://miamioh.instructure.com/courses/142177/quizzes/371145}{Canvas (click here)} and answer the questions. **Due March 04, 2021 [11:59 PM, Ohio local time]** 

**What/Why/Prep?** The purpose of this assignment is to evaluate your understanding and retention of Holt's method. To reinforce your understanding of the covered material, I also suggest reading Chapter 3.1-3.4 of the book.

**General Guidelines:**  

\vspace{-0.5\baselineskip}

  - Individual assignment.  
  - This is **NOT** a timed assignment.    
  - Proctorio is NOT required for this assignment.  
  - You will need to have R installed (or accessible through the \href{https://virtualpc.fsb.miamioh.edu/RDWeb/Pages/en-US/default.aspx}{Remote Desktop})


### Graded Assignment 09: Evaluating your Understanding

Please go to \href{https://miamioh.instructure.com/courses/142177/quizzes/371656}{Canvas (click here)} and answer the questions. **The assignment will be online on March 2, 2021 [8:00 AM] and is due March 04, 2021 [11:59 PM, Ohio local time].**

**What/Why/Prep?** The purpose of this assignment is to evaluate your understanding and retention of seasonal decomposition. To reinforce your understanding of the covered material, I also suggest reading Chapter 4.1-4.4 of the book.

**General Guidelines:**  

\vspace{-0.5\baselineskip}

  - Individual assignment.  
  - This is **NOT** a timed assignment.    
  - Proctorio is NOT required for this assignment.  
  - You will need to have R installed (or accessible through the \href{https://virtualpc.fsb.miamioh.edu/RDWeb/Pages/en-US/default.aspx}{Remote Desktop})


---

\maketitle