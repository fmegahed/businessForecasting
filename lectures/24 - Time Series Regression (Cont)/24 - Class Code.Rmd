---
title: "24 - Class Notes"
author: "Fadel M Megahed"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
    paged_df: true
    theme: simplex
    code_folding: show
    code_download: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Learning Objectives for Today's Class {-}

  1. Conduct tests for significance of individual regression coefficients.  
  2. Use a simple linear regression model for trend adjustment.
  3. Interpret regression diagnostic plots.  
  4. Create prediction intervals for individual values of the response variable.  
  5. Discuss Exam 03 (Not in R).

# Required Packages {-}
In the code chunk below, we use the `pacman` package to load the required packages and install them if necessary.

```{r packages}
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(tidyverse, 
               magrittr, # for the two-way pipe
               fpp2, # accuracy() function, Arima(), auto.arima(),
               astsa, # package is for the required data
               plotly, # for interactive graphs
               stargazer) 
```

# Recap of What we Covered Last Class

## Loading the J&J Data
```{r jj}
jj = jj # assigning the jj data (from astsa) to an object of the same name
class(jj) # to check and see if the class is a ts object
frequency(jj) # to check the frequency --> based on the print out (=4)
jj
p = autoplot(jj) + theme_bw()
ggplotly(p)
```

Based on the plot, we can make three observations:  

  (1) The data is not linear, which means that fitting a linear regression directly to this data is not prudent.  
  (2) The variance was not constant as it increased over time (with larger values of the EPS).  
  (3) The data is exhibting a seasonal pattern (fourth quarter is consistently below the values for q3 and q1).
  

## Transforming the J&J TS

```{r logtransform}
log_jj = log(jj)
p2 = autoplot(log_jj)
ggplotly(p2) # a linear regression line is probably okay (the variance is more stable with the transformation)
```


## Time as the Independent Variable
```{r extractingTime}
t = time(log_jj) # time makes a decimal date from the ts (if freq  >  1)
t
```

## Fit the Model

```{r model}
model = lm (log_jj ~ t) # t is the ind variable and log_jj is the response
names(model)
summary(model)
```

**Let us recap some of the outputs.** 

### Regression Equation
```{r extractingValuesForEquation}
intercept = summary(model) %>% .[['coefficients']] %>% .['(Intercept)', 'Estimate']
beta1 = summary(model) %>% .[['coefficients']] %>% .['t', 'Estimate']
sigma = summary(model) %>% .[['sigma']]
```
$y_t = `r round(intercept, 4)` + `r round(beta1, 4)`t + \varepsilon, \, \text{where } \varepsilon\sim\mathcal N(0, ~ `r round(sigma, 4)`^2)$ 

### Predicted/Fitted Values and Residuals
```{r fittedVals}
fit = model$fitted.values
res = model$residuals 
```

### Multiple R2 [NEW]
```{r multipleR2}
modelSummary = summary(model)
```



### Tests for Significance




# Use a simple linear regression model for trend adjustment.




# Interpret regression diagnostic plots.  




# Create prediction intervals for individual values of the response variable.




# Discuss Exam 03 (Not in R)

